<html class="js flexbox fontface" lang="en" style=""><head><head><meta charset="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Real World OCaml</title><link rel="stylesheet" href="css/app.css"/><script src="js/min/modernizr-min.js"></script><script src="//use.typekit.net/gfj8wez.js"></script><script>try{Typekit.load();}catch(e){}</script></head></head><body><div class="title-bar"><div class="title"><h1>Real World OCaml</h1><h5>2<sup>nd</sup> Edition (in progress)</h5><nav><a href="index.html">Home</a><a href="toc.html">Table of Contents</a><a href="faqs.html">FAQs</a><a href="install.html">Install</a><a href="https://ocaml.janestreet.com/ocaml-core/">API Docs</a></nav></div></div><div class="wrap"><div class="left-column"><a href="toc.html" class="to-chapter"><small>Back</small><h5>Table of Contents</h5></a></div><article class="main-body">
    <section xmlns="http://www.w3.org/1999/xhtml" id="understanding-the-garbage-collector" data-type="chapter">
      <h1>Understanding the Garbage Collector</h1>

      <p>
	We've described the runtime format of individual OCaml
	variables earlier, in <a href="20-runtime-memory-layout.html#memory-representation-of-values" data-type="xref">Chapter 20, Memory Representation Of Values</a>. When you
	execute your program, OCaml manages the lifecycle of these
	variables by regularly scanning allocated values and freeing
	them when they're no longer needed. This in turn means that
	your applications don't need to manually implement memory
	management, and it greatly reduces the likelihood of memory
	leaks creeping into your code.

	<a data-type="indexterm" data-primary="memory" data-secondary="memory management">&nbsp;</a></p>

      <p>
	The OCaml runtime is a C library that provides routines that
	can be called from running OCaml programs. The runtime manages
	a <em>heap</em>, which is a collection of memory regions that
	it obtains from the operating system. The runtime uses this
	memory to hold <em>heap blocks</em> that it fills up with OCaml
	values in response to allocation requests by the OCaml
	program.

	<a data-type="indexterm" data-primary="values" data-secondary="allocation requests and">&nbsp;</a>
	<a data-type="indexterm" data-primary="heaps" data-secondary="heap blocks">&nbsp;</a>
	<a data-type="indexterm" data-primary="heaps" data-secondary="definition of">&nbsp;</a></p>

      <section id="mark-and-sweep-garbage-collection" data-type="sect1">
	<h1>Mark and Sweep Garbage Collection</h1>

	<p>
	  When there isn't enough memory available to satisfy an
	  allocation request from the pool of allocated heap blocks,
	  the runtime system invokes the garbage collector (GC). An
	  OCaml program can't explicitly free a value when it is done
	  with it. Instead, the GC regularly determines which values
	  are <em>live</em> and which values are <em>dead</em>, i.e.,
	  no longer in use. Dead values are collected and their memory
	  made available for reuse by the application.

	  <a data-type="indexterm" data-primary="mark and sweep garbage collection">&nbsp;</a>
	  <a data-type="indexterm" data-primary="garbage collection" data-secondary="mark and sweep collection">&nbsp;</a></p>

	<p>
	  The GC doesn't keep constant track of values as they are
	  allocated and used. Instead, it regularly scans them by
	  starting from a set of <em>root</em> values that the
	  application always has access to (such as the stack). The GC
	  maintains a directed graph in which heap blocks are nodes,
	  and there is an edge from heap block <code>b1</code> to heap
	  block <code>b2</code> if some field of <code>b1</code> is a
	  pointer to <code>b2</code>.</p>

	<p>
	  All blocks reachable from the roots by following edges in
	  the graph must be retained, and unreachable blocks can be
	  reused by the application. The algorithm used by OCaml to
	  perform this heap traversal is commonly known as <em>mark and
	    sweep</em> garbage collection, and we'll explain it further
	  now.</p>
      </section>

      <section id="generational-garbage-collection" data-type="sect1">
	<h1>Generational Garbage Collection</h1>

	<p>
	  The usual OCaml programming style involves allocating many
	  small variables that are used for a short period of time and
	  then never accessed again. OCaml takes advantage of this fact
	  to improve performance by using a <em>generational</em>
	  GC.

	  <a data-type="indexterm" data-primary="generational garbage collection">&nbsp;</a>
	  <a data-type="indexterm" data-primary="garbage collection" data-secondary="generational collection">&nbsp;</a></p>

	<p>
	  A generational GC maintains separate memory regions to
	  hold blocks based on how long the blocks have been live.
	  OCaml's heap is split into two such regions:

	  <a data-type="indexterm" data-primary="heaps" data-secondary="regions of">&nbsp;</a></p>

	<ul>
          <li>
            <p>
	      A small, fixed-size <em>minor heap</em> where most
              blocks are initially allocated</p>
          </li>

          <li>
            <p>
	      A larger, variable-size <em>major heap</em> for blocks
              that have been live longer</p>
          </li>
	</ul>

	<p>
	  A typical functional programming style means that young
	  blocks tend to die young and old blocks tend to stay around
	  for longer than young ones. This is often referred to as the
	  <em>generational hypothesis</em>.

	  <a data-type="indexterm" data-primary="generational hypothesis">&nbsp;</a></p>

	<p>
	  OCaml uses different memory layouts and garbage-collection
	  algorithms for the major and minor heaps to account for this
	  generational difference. We'll explain how they differ in
	  more detail next.

	  <a data-type="indexterm" data-primary="OCAMLRUNPARAM">&nbsp;</a>
	  <a data-type="indexterm" data-primary="Gc module" data-seealso="garbage collection">&nbsp;</a></p>

	<aside data-type="sidebar">
          <h5>The Gc Module and OCAMLRUNPARAM</h5>

          <p>
	    OCaml provides several mechanisms to query and alter the
            behavior of the runtime system. The <code>Gc</code> module
            provides this functionality from within OCaml code, and
            we'll frequently refer to it in the rest of the chapter. As
            with several other standard library modules, Core alters
            the <code>Gc</code> interface from the standard OCaml
            library. We'll assume that you've opened
            <code>Core</code> in our explanations.</p>

          <p>
	    You can also control the behavior of OCaml programs by
            setting the <code>OCAMLRUNPARAM</code> environment variable
            before launching your application. This lets you set GC
            parameters without recompiling, for example to benchmark
            the effects of different settings. The format of
            <code>OCAMLRUNPARAM</code> is documented in the <a href="http://caml.inria.fr/pub/docs/manual-ocaml/manual024.html">
              OCaml manual</a>.</p>
	</aside>
      </section>

      <section id="the-fast-minor-heap" data-type="sect1">
	<h1>The Fast Minor Heap</h1>

	<p>
	  The minor heap is where most of your short-lived values
	  are held. It consists of one contiguous chunk of virtual
	  memory containing a sequence of OCaml blocks. If there is
	  space, allocating a new block is a fast, constant-time
	  operation that requires just a couple of CPU
	  instructions.

	  <a data-type="indexterm" data-primary="heaps" data-secondary="minor heaps">&nbsp;</a>
	  <a data-type="indexterm" data-primary="minor heaps" data-secondary="garbage collection in">&nbsp;</a>
	  <a data-type="indexterm" data-primary="copying collection">&nbsp;</a>
	  <a data-type="indexterm" data-primary="garbage collection" data-secondary="of short-lived values">&nbsp;</a></p>

	<p>
	  To garbage-collect the minor heap, OCaml uses <em>copying
	    collection</em> to move all live blocks in the minor heap to
	  the major heap. This takes work proportional to the number of
	  live blocks in the minor heap, which is typically small
	  according to the generational hypothesis. The minor
	  collection <em>stops the world</em> (that it, halts the
	  application) while it runs, which is why it's so important
	  that it complete quickly to let the application resume
	  running with minimal interruption.</p>

	<section id="allocating-on-the-minor-heap" data-type="sect2">
          <h2>Allocating on the Minor Heap</h2>

          <p>
	    The minor heap is a contiguous chunk of virtual memory
            that is usually a few megabytes in size so that it can be
            scanned quickly.

	    <a data-type="indexterm" data-primary="minor heaps" data-secondary="allocating on">&nbsp;</a></p>

          <figure style="float: 0">
            <img src="images/gc/minor_heap.png"/>
          </figure>

          <p>
	    The runtime stores the boundaries of the minor heap in
            two pointers that delimit the start and end of the heap
            region (<code>caml_young_start</code> and
            <code>caml_young_end</code>, but we will drop the
            <code>caml_young</code> prefix for brevity). The
            <code>base</code> is the memory address returned by the
            system <code>malloc</code>, and <code>start</code> is
            aligned against the next nearest word boundary from
            <code>base</code> to make it easier to store OCaml
            values.</p>

          <p>
	    In a fresh minor heap, the <code>limit</code> equals the
            <code>start</code>, and the current <code>ptr</code> will
            equal the <code>end</code>. <code>ptr</code> decreases as
            blocks are allocated until it reaches <code>limit</code>,
            at which point a minor garbage collection is triggered.</p>

          <p>
	    Allocating a block in the minor heap just requires
            <code>ptr</code> to be decremented by the size of the block
            (including the header) and a check that it's not less than
            <code>limit</code>. If there isn't enough space left for
            the block without decrementing past <code>limit</code>, a
            minor garbage collection is triggered. This is a very fast
            check (with no branching) on most CPU architectures.</p>

          <p>
	    You may wonder why <code>limit</code> is required at
            all, since it always seems to equal <code>start</code>.
            It's because the easiest way for the runtime to schedule a
            minor heap collection is by setting <code>limit</code> to
            equal <code>end</code>. The next allocation will never have
            enough space after this is done and will always trigger a
            garbage collection. There are various internal reasons for
            such early collections, such as handling pending UNIX
            signals, and they don't ordinarily matter for application
            code.

	    <a data-type="indexterm" data-primary="minor heaps" data-secondary="setting size of">&nbsp;</a></p>

          <div data-type="note">
            <h1>Setting the Size of the Minor Heap</h1>

            <p>
	      The default minor heap size in OCaml is normally 2 MB
              on 64-bit platforms, but this is increased to 8 MB if you
              use Core (which generally prefers default settings that
              improve performance, but at the cost of a bigger memory
              profile). This setting can be overridden via the
              <code>s=&lt;words&gt;</code> argument to
              <code>OCAMLRUNPARAM</code>. You can change it after the
              program has started by calling the <code>Gc.set</code>
              function:</p>
          </div>

          <div class="highlight"><pre><span></span><span class="o">#</span> <span class="k">open</span> <span class="nc">Core_kernel</span><span class="o">;;</span>
</pre><pre><span></span><span class="o">#</span> <span class="k">let</span> <span class="o">c</span> <span class="o">=</span> <span class="nn">Gc</span><span class="p">.</span><span class="n">get</span> <span class="bp">()</span> <span class="o">;;</span>
</pre><pre class="ge"><span></span><span class="k">val</span> <span class="o">c</span> <span class="o">:</span> <span class="nn">Gc</span><span class="p">.</span><span class="n">control</span> <span class="o">=</span>
  <span class="o">{</span><span class="nn">Core_kernel</span><span class="p">.</span><span class="nn">Gc</span><span class="p">.</span><span class="nn">Control</span><span class="p">.</span><span class="n">minor_heap_size</span> <span class="o">=</span> <span class="o">262</span><span class="mi">144</span><span class="o">;</span>
   <span class="o">ma</span><span class="n">jor_heap_increment</span> <span class="o">=</span> <span class="mi">15</span><span class="o">;</span> <span class="o">space_o</span><span class="n">verhead</span> <span class="o">=</span> <span class="o">80;</span> <span class="n">verbose</span> <span class="o">=</span> <span class="o">0;</span>
   <span class="o">ma</span><span class="n">x_overhead</span> <span class="o">=</span> <span class="o">500;</span> <span class="o">stack_limit</span> <span class="o">=</span> <span class="mi">1048576</span><span class="o">;</span> <span class="o">allocation_policy</span> <span class="o">=</span> <span class="o">0;</span>
   <span class="n">window_size</span> <span class="o">=</span> <span class="mi">1</span><span class="o">}</span>
</pre><pre><span></span><span class="o">#</span> <span class="nn">Gc</span><span class="p">.</span><span class="n">tune</span> <span class="o">~minor_heap_size:(262</span><span class="mi">144</span> <span class="o">*</span> <span class="o">2)</span> <span class="bp">()</span> <span class="o">;;</span>
</pre><pre class="ge"><span></span><span class="o">-</span> <span class="o">:</span> <span class="o">unit</span> <span class="o">=</span> <span class="bp">()</span>
</pre></div>

          <p>
	    Changing the GC size dynamically will trigger an
            immediate minor heap collection. Note that Core increases
            the default minor heap size from the standard OCaml
            installation quite significantly, and you'll want to reduce
            this if running in very memory-constrained
            environments.</p>
	</section>
      </section>

      <section id="the-long-lived-major-heap" data-type="sect1">
	<h1>The Long-Lived Major Heap</h1>

	<p>
	  The major heap is where the bulk of the longer-lived and
	  larger values in your program are stored. It consists of any
	  number of noncontiguous chunks of virtual memory, each
	  containing live blocks interspersed with regions of free
	  memory. The runtime system maintains a free-list data
	  structure that indexes all the free memory that it has
	  allocated, and uses it to satisfy allocation requests for
	  OCaml blocks.

	  <a data-type="indexterm" data-primary="garbage collection" data-secondary="mark and sweep collection">&nbsp;</a>
	  <a data-type="indexterm" data-primary="mark and sweep garbage collection">&nbsp;</a>
	  <a data-type="indexterm" data-primary="major heaps" data-secondary="garbage collection in">&nbsp;</a>
	  <a data-type="indexterm" data-primary="heaps" data-secondary="major heaps" id="Hmh">&nbsp;</a>
	  <a data-type="indexterm" data-primary="garbage collection" data-secondary="of longer-lived values">&nbsp;</a></p>

	<p>
	  The major heap is typically much larger than the minor
	  heap and can scale to gigabytes in size. It is cleaned via a
	  mark-and-sweep garbage collection algorithm that operates in
	  several phases:</p>

	<ul>
          <li>
            <p>
	      The <em>mark</em> phase scans the block graph and
              marks all live blocks by setting a bit in the tag of the
              block header (known as the <em>color</em> tag).</p>
          </li>

          <li>
            <p>
	      The <em>sweep</em> phase sequentially scans the heap
              chunks and identifies dead blocks that weren't marked
              earlier.</p>
          </li>

          <li>
            <p>
	      The <em>compact</em> phase relocates live blocks into
              a freshly allocated heap to eliminate gaps in the free
              list. This prevents the fragmentation of heap blocks in
              long-running programs and normally occurs much less
              frequently than the mark and sweep <span class="keep-together">phases</span>.</p>
          </li>
	</ul>

	<p>
	  A major garbage collection must also stop the world to
	  ensure that blocks can be moved around without this being
	  observed by the live application. The mark-and-sweep phases
	  run incrementally over slices of the heap to avoid pausing
	  the application for long <span class="keep-together">periods</span> of time, and also precede each
	  slice with a fast minor collection. Only the compaction phase
	  touches all the memory in one go, and is a relatively rare
	  operation.</p>

	<section id="allocating-on-the-major-heap" data-type="sect2">
          <h2>Allocating on the Major Heap</h2>

          <p>
	    The major heap consists of a singly linked list of
            contiguous memory chunks sorted in increasing order of
            virtual address. Each chunk is a single memory region
            allocated via <em>malloc(3)</em> and consists of a header
            and data area which contains OCaml heap chunks. A heap
            chunk header contains:

	    <a data-type="indexterm" data-primary="malloc(3)">&nbsp;</a>
	    <a data-type="indexterm" data-primary="major heaps" data-secondary="allocating on">&nbsp;</a></p>

          <ul>
            <li>
              <p>
		The <em>malloc</em>ed virtual address of the memory
		region containing the chunk</p>
            </li>

            <li>
              <p>
		The size in bytes of the data area</p>
            </li>

            <li>
              <p>
		An allocation size in bytes used during heap
		compaction to merge small blocks to defragment the
		heap</p>
            </li>

            <li>
              <p>
		A link to the next heap chunk in the list</p>
            </li>
          </ul>

          <p>
	    Each chunk's data area starts on a page boundary, and
            its size is a multiple of the page size (4 KB). It contains
            a contiguous sequence of heap blocks that can be as small
            as one or two 4 KB pages, but are usually allocated in 1 MB
            chunks (or 512 KB on 32-bit architectures).

	    <a data-type="indexterm" data-primary="major heaps" data-secondary="controlling growth of">&nbsp;</a></p>

          <div data-type="note">
            <h1>Controlling Major Heap Growth</h1>

            <p>
	      The <code>Gc</code> module uses the
              <code>major_heap_increment</code> value to control the
              major heap growth. This defines the number of words to
              add to the major heap per expansion and is the only
              memory allocation operation that the operating system
              observes from the OCaml runtime after initial startup
              (since the minor is fixed in size).</p>

            <p>
	      If you anticipate allocating some large OCaml values
              or many small values in one go, then setting the heap
              increment to a larger value will improve performance by
              reducing the amount of heap resizing required in order to
              satisfy the allocation requests. A small increment may
              result in lots of smaller heap chunks spread across
              different regions of virtual memory that require more
              housekeeping in the OCaml runtime to keep track of
              them:</p>
          </div>
          <div class="highlight"><pre><span></span><span class="o">#</span> <span class="nn">Gc</span><span class="p">.</span><span class="n">tune</span> <span class="o">~ma</span><span class="n">jor_heap_increment</span><span class="o">:(</span><span class="mi">1000448</span> <span class="o">*</span> <span class="o">4)</span> <span class="bp">()</span> <span class="o">;;</span>
</pre><pre class="ge"><span></span><span class="o">-</span> <span class="o">:</span> <span class="o">unit</span> <span class="o">=</span> <span class="bp">()</span>
</pre></div>

          <p>
	    Allocating an OCaml value on the major heap first checks
            the free list of blocks for a suitable region to place it.
            If there isn't enough room on the free list, the runtime
            expands the major heap by allocating a fresh heap chunk
            that will be large enough. That chunk is then added to the
            free list, and the free list is checked again (and this
            time will definitely succeed).</p>

          <p>
	    Remember that most allocations to the major heap will go
            via the minor heap and only be promoted if they are still
            used by the program after a minor collection. The one
            exception to this is for values larger than 256 words (that
            is, 2 KB on 64-bit platforms). These will be allocated
            directly on the major heap, since an allocation on the
            minor heap would likely trigger an immediate collection and
            copy it to the major heap anyway.</p>
	</section>

	<section id="memory-allocation-strategies" data-type="sect2">
          <h2>Memory Allocation Strategies</h2>

          <p>
	    The major heap does its best to manage memory allocation
            as efficiently as possible and relies on heap compaction to
            ensure that memory stays contiguous and unfragmented. The
            default allocation policy normally works fine for most
            applications, but it's worth bearing in mind that there are
            other options, too.

	    <a data-type="indexterm" data-primary="memory" data-secondary="major heap allocation strategies">&nbsp;</a>
	    <a data-type="indexterm" data-primary="major heaps" data-secondary="memory allocation strategies">&nbsp;</a></p>

          <p>
	    The free list of blocks is always checked first when
            allocating a new block in the major heap. The default free
            list search is called <em>next-fit allocation</em>, with an
            alternative <em>first-fit</em> algorithm also
            available.

	    <a data-type="indexterm" data-primary="first-fit allocation">&nbsp;</a>
	    <a data-type="indexterm" data-primary="next-fit allocation">&nbsp;</a></p>

          <section id="next-fit-allocation" data-type="sect3">
            <h3>Next-fit allocation</h3>

            <p>
	      Next-fit allocation keeps a pointer to the block in
              the free list that was most recently used to satisfy a
              request. When a new request comes in, the allocator
              searches from the next block to the end of the free list,
              and then from the beginning of the free list up to that
              block.</p>

            <p>
	      Next-fit allocation is the default allocation
              strategy. It's quite a cheap allocation mechanism, since
              the same heap chunk can be reused across allocation
              requests until it runs out. This in turn means that there
              is good memory locality to use CPU caches better.</p>
          </section>

          <section id="first-fit-allocation" data-type="sect3">
            <h3>First-fit allocation</h3>

            <p>
	      If your program allocates values of many varied sizes,
              you may sometimes find that your free list becomes
              fragmented. In this situation, the GC is forced to
              perform an expensive compaction despite there being free
              chunks, since none of the chunks alone are big enough to
              satisfy the request.</p>

            <p>
	      First-fit allocation focuses on reducing memory
              fragmentation (and hence the number of compactions), but
              at the expense of slower memory allocation. Every
              allocation scans the free list from the beginning for a
              suitable free chunk, instead of reusing the most recent
              heap chunk as the next-fit allocator does.

	      <a data-type="indexterm" data-primary="memory" data-secondary="reducing fragmentation of">&nbsp;</a></p>

            <p>
	      For some workloads that need more real-time behavior
              under load, the reduction in the frequency of heap
              compaction will outweigh the extra allocation cost.</p>

            <div data-type="note">
              <h1>Controlling the Heap Allocation Policy</h1>

              <p>
		You can set the heap allocation policy via the
		<code>Gc.allocation_policy</code> field. A value of
		<code>0</code> (the default) sets it to next-fit, and
		<code>1</code> to the first-fit allocator.</p>

              <p>
		The same behavior can be controlled at runtime by
		setting <code>a=0</code> or <code>a=1</code> in
		<code>OCAMLRUNPARAM</code>.</p>
            </div>
          </section>
	</section>

	<section id="marking-and-scanning-the-heap" data-type="sect2">
          <h2>Marking and Scanning the Heap</h2>

          <p>
	    The marking process can take a long time to run over the
            complete major heap and has to pause the main application
            while it's active. It therefore runs incrementally by
            marking the heap in <em>slices</em>. Each value in the heap
            has a 2-bit <em>color</em> field in its header that is used
            to store information about whether the value has been
            marked so that the GC can resume easily between slices.

	    <a data-type="indexterm" data-primary="major heaps" data-secondary="marking and scanning">&nbsp;</a></p>

          <table>
            <caption>
              Tag color statuses
            </caption>

            <thead>
              <tr>
		<th>Tag color</th>

		<th>Block status</th>
              </tr>
            </thead>

            <tbody>
              <tr>
		<td>Blue</td>

		<td>On the free list and not currently in use</td>
              </tr>

              <tr>
		<td>White (during marking)</td>

		<td>Not reached yet, but possibly reachable</td>
              </tr>

              <tr>
		<td>White (during sweeping)</td>

		<td>Unreachable and can be freed</td>
              </tr>

              <tr>
		<td>Gray</td>

		<td>Reachable, but its fields have not been
		  scanned</td>
              </tr>

              <tr>
		<td>Black</td>

		<td>Reachable, and its fields have been scanned</td>
              </tr>
            </tbody>
          </table>

          <p>
	    The color tags in the value headers store most of the
            state of the marking process, allowing it to be paused and
            resumed later. The GC and application alternate between
            marking a slice of the major heap and actually getting on
            with executing the program logic. The OCaml runtime
            calculates a sensible value for the size of each major heap
            slice based on the rate of allocation and available
            memory.</p>

          <p>
	    The marking process starts with a set of <em>root</em>
            values that are always live (such as the application
            stack). All values on the heap are initially marked as
            white values that are possibly reachable but haven't been
            scanned yet. It recursively follows all the fields in the
            roots via a depth-first search, and pushes newly
            encountered white blocks onto an intermediate stack of
            <em>gray values</em> while it follows their fields. When a
            gray value's fields have all been followed, it is popped
            off the stack and colored black.

	    <a data-type="indexterm" data-primary="root values">&nbsp;</a>
	    <a data-type="indexterm" data-primary="gray values">&nbsp;</a></p>

          <p>
	    This process is repeated until the gray value stack is
            empty and there are no further values to mark. There's one
            important edge case in this process, though. The gray value
            stack can only grow to a certain size, after which the GC
            can no longer recurse into intermediate values since it has
            nowhere to store them while it follows their fields. If
            this happens, the heap is marked as <em>impure</em> and a
            more expensive check is initiated once the existing gray
            values have been processed.

	    <a data-type="indexterm" data-primary="impure heaps">&nbsp;</a></p>

          <p>
	    To mark an impure heap, the GC first marks it as pure
            and walks through the entire heap block-by-block in
            increasing order of memory address. If it finds a gray
            block, it adds it to the gray list and recursively marks it
            using the usual strategy for a pure heap. Once the scan of
            the complete heap is finished, the mark phase checks again
            whether the heap has again become impure and repeats the
            scan until it is pure again. These full-heap scans will
            continue until a successful scan completes without
            overflowing the gray list.

	    <a data-type="indexterm" data-primary="major heaps" data-secondary="controlling collections">&nbsp;</a></p>

          <div data-type="note">
            <h1>Controlling Major Heap Collections</h1>

            <p>
	      You can trigger a single slice of the major GC via the
              <code>major_slice</code> call. This performs a minor
              collection first, and then a single slice. The size of
              the slice is normally automatically computed by the GC to
              an appropriate value and returns this value so that you
              can modify it in future calls if necessary:</p>
          </div>
          <div class="highlight"><pre><span></span><span class="o">#</span> <span class="nn">Gc</span><span class="p">.</span><span class="n">major_slice</span> <span class="o">0</span> <span class="o">;;</span>
</pre><pre class="ge"><span></span><span class="o">-</span> <span class="o">:</span> <span class="o">int</span> <span class="o">=</span> <span class="o">0</span>
</pre><pre><span></span><span class="o">#</span> <span class="nn">Gc</span><span class="p">.</span><span class="n">full_major</span> <span class="bp">()</span> <span class="o">;;</span>
</pre><pre class="ge"><span></span><span class="o">-</span> <span class="o">:</span> <span class="o">unit</span> <span class="o">=</span> <span class="bp">()</span>
</pre></div>

          <p>
	    The <code>space_overhead</code> setting controls how
            aggressive the GC is about setting the slice size to a
            large size. This represents the proportion of memory used
            for live data that will be "wasted" because the GC doesn't
            immediately collect unreachable blocks. Core defaults this
            to <code>100</code> to reflect a typical system that isn't
            overly memory-constrained. Set this even higher if you have
            lots of memory, or lower to cause the GC to work harder and
            collect blocks faster at the expense of using more CPU
            time.</p>
	</section>

	<section id="heap-compaction" data-type="sect2">
          <h2>Heap Compaction</h2>

          <p>
	    After a certain number of major GC cycles have
            completed, the heap may begin to be fragmented due to
            values being deallocated out of order from how they were
            allocated. This makes it harder for the GC to find a
            contiguous block of memory for fresh allocations, which in
            turn would require the heap to be grown unnecessarily.

	    <a data-type="indexterm" data-primary="memory" data-secondary="reducing fragmentation of">&nbsp;</a>
	    <a data-type="indexterm" data-primary="compaction">&nbsp;</a>
	    <a data-type="indexterm" data-primary="major heaps" data-secondary="heap compaction">&nbsp;</a></p>

          <p>
	    The heap compaction cycle avoids this by relocating all
            the values in the major heap into a fresh heap that places
            them all contiguously in memory again. A naive
            implementation of the algorithm would require extra memory
            to store the new heap, but OCaml performs the compaction in
            place within the existing heap.</p>

          <div data-type="note">
            <h1>Controlling Frequency of Compactions</h1>

            <p>
	      The <code>max_overhead</code> setting in the
              <code>Gc</code> module defines the connection between
              free memory and allocated memory after which compaction
              is activated.</p>

            <p>
	      A value of <code>0</code> triggers a compaction after
              every major garbage collection cycle, whereas the maximum
              value of <code>1000000</code> disables heap compaction
              completely. The default settings should be fine unless
              you have unusual allocation patterns that are causing a
              higher-than-usual rate of compactions:</p>
          </div>
          <div class="highlight"><pre><span></span><span class="o">#</span> <span class="nn">Gc</span><span class="p">.</span><span class="n">tune</span> <span class="o">~ma</span><span class="n">x_overhead</span><span class="o">:0</span> <span class="bp">()</span> <span class="o">;;</span>
</pre><pre class="ge"><span></span><span class="o">-</span> <span class="o">:</span> <span class="o">unit</span> <span class="o">=</span> <span class="bp">()</span>
</pre></div>
	</section>

	<section id="inter-generational-pointers" data-type="sect2">
          <h2>Intergenerational Pointers</h2>

          <p>
	    One complexity of generational collection arises from
            the fact that minor heap sweeps are much more frequent than
            major heap collections. In order to know which blocks in
            the minor heap are live, the collector must track which
            minor-heap blocks are directly pointed to by major-heap
            blocks. Without this information, each minor collection
            would also require scanning the much larger major heap.

	    <a data-type="indexterm" data-primary="pointers" data-secondary="intergenerational pointers">&nbsp;</a>
	    <a data-type="indexterm" data-primary="intergenerational pointers">&nbsp;</a>
	    <a data-type="indexterm" data-primary="major heaps" data-secondary="intergenerational pointers in">&nbsp;</a></p>

          <p>
	    OCaml maintains a set of such <em>intergenerational
              pointers</em> to avoid this dependency between a major and
            minor heap collection. The compiler introduces a write
            barrier to update this so-called <em>remembered set</em>
            whenever a major-heap block is modified to point at a
            minor-heap block.

	    <a data-type="indexterm" data-primary="write barriers">&nbsp;</a>
	    <a data-type="indexterm" data-primary="remembered sets">&nbsp;</a></p>

          <section id="the-mutable-write-barrier" data-type="sect3">
            <h3>The mutable write barrier</h3>

            <p>
	      The write barrier can have profound implications for
              the structure of your code. It's one of the reasons using
              immutable data structures and allocating a fresh copy
              with changes can sometimes be faster than mutating a
              record in place.</p>

            <p>
	      The OCaml compiler keeps track of any mutable types
              and adds a call to the runtime <code>caml_modify</code>
              function before making the change. This checks the
              location of the target write and the value it's being
              changed to, and ensures that the remembered set is
              consistent. Although the write barrier is reasonably
              efficient, it can sometimes be slower than simply
              allocating a fresh value on the fast minor heap and doing
              some extra minor collections.</p>

            <p>
	      Let's see this for ourselves with a simple test
              program. You'll need to install the Core benchmarking
              suite via <code>opam install core_bench</code> before you
              compile this code:</p>
            <div class="highlight"><pre><span></span><span class="k">open</span> <span class="nc">Core</span>
<span class="k">open</span> <span class="nc">Core_bench</span>

<span class="k">type</span> <span class="o">t</span><span class="mi">1</span> <span class="o">=</span> <span class="o">{</span> <span class="k">mutable</span> <span class="o">iters</span><span class="mi">1</span><span class="o">:</span> <span class="o">int;</span> <span class="k">mutable</span> <span class="o">count</span><span class="mi">1</span><span class="o">:</span> <span class="o">float</span> <span class="o">}</span>
<span class="k">type</span> <span class="o">t2</span> <span class="o">=</span> <span class="o">{</span> <span class="o">iters2:</span> <span class="o">int;</span> <span class="o">count2:</span> <span class="o">float</span> <span class="o">}</span>

<span class="k">let</span> <span class="k">rec</span> <span class="o">test_mutable</span> <span class="o">t</span><span class="mi">1</span> <span class="o">=</span>
  <span class="k">match</span> <span class="o">t</span><span class="mi">1</span><span class="o">.iters</span><span class="mi">1</span> <span class="k">with</span>
  <span class="o">|0</span> <span class="o">-&gt;</span> <span class="bp">()</span>
  <span class="o">|_</span> <span class="o">-&gt;</span>
    <span class="o">t</span><span class="mi">1</span><span class="o">.iters</span><span class="mi">1</span> <span class="o">&lt;-</span> <span class="o">t</span><span class="mi">1</span><span class="o">.iters</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span><span class="o">;</span>
    <span class="o">t</span><span class="mi">1</span><span class="o">.count</span><span class="mi">1</span> <span class="o">&lt;-</span> <span class="o">t</span><span class="mi">1</span><span class="o">.count</span><span class="mi">1</span> <span class="o">+.</span> <span class="mi">1</span><span class="o">.0;</span>
    <span class="o">test_mutable</span> <span class="o">t</span><span class="mi">1</span>

<span class="k">let</span> <span class="k">rec</span> <span class="o">test_immutable</span> <span class="o">t2</span> <span class="o">=</span>
  <span class="k">match</span> <span class="o">t2.iters2</span> <span class="k">with</span>
  <span class="o">|0</span> <span class="o">-&gt;</span> <span class="bp">()</span>
  <span class="o">|n</span> <span class="o">-&gt;</span>
    <span class="k">let</span> <span class="o">iters2</span> <span class="o">=</span> <span class="o">n</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">in</span>
    <span class="k">let</span> <span class="o">count2</span> <span class="o">=</span> <span class="o">t2.count2</span> <span class="o">+.</span> <span class="mi">1</span><span class="o">.0</span> <span class="k">in</span>
    <span class="o">test_immutable</span> <span class="o">{</span> <span class="o">iters2;</span> <span class="o">count2</span> <span class="o">}</span>

<span class="k">let</span> <span class="bp">()</span> <span class="o">=</span>
  <span class="k">let</span> <span class="o">iters</span> <span class="o">=</span> <span class="mi">1000000</span> <span class="k">in</span>
  <span class="k">let</span> <span class="o">tests</span> <span class="o">=</span> <span class="o">[</span>
    <span class="nn">Bench</span><span class="p">.</span><span class="nn">Test</span><span class="p">.</span><span class="n">create</span> <span class="o">~name:</span><span class="s2">&quot;mutable&quot;</span> 
      <span class="o">(</span><span class="k">fun</span> <span class="bp">()</span> <span class="o">-&gt;</span> <span class="o">test_mutable</span> <span class="o">{</span> <span class="o">iters</span><span class="mi">1</span><span class="o">=iters;</span> <span class="o">count</span><span class="mi">1</span><span class="o">=0.0</span> <span class="o">});</span>
    <span class="nn">Bench</span><span class="p">.</span><span class="nn">Test</span><span class="p">.</span><span class="n">create</span> <span class="o">~name:</span><span class="s2">&quot;immutable&quot;</span>
      <span class="o">(</span><span class="k">fun</span> <span class="bp">()</span> <span class="o">-&gt;</span> <span class="o">test_immutable</span> <span class="o">{</span> <span class="o">iters2=iters;</span> <span class="o">count2=0.0</span> <span class="o">})</span>
  <span class="o">]</span> <span class="k">in</span>
  <span class="nn">Bench</span><span class="p">.</span><span class="n">make_command</span> <span class="o">tests</span> <span class="o">|&gt;</span> <span class="nn">Command</span><span class="p">.</span><span class="n">run</span>
</pre></div>

            <p>
	      This program defines a type <code>t1</code> that is
              mutable and <code>t2</code> that is immutable. The
              benchmark loop iterates over both fields and increments a
              counter. Compile and execute this with some extra options
              to show the amount of garbage collection occurring:</p>
            <div class="highlight"><pre>(jbuild_version 1)

(executable
  ((name barrier_bench)
   (modules barrier_bench)
   (libraries (core core_bench))
  )
)

(executable
  ((name finalizer)
   (modules finalizer)
   (libraries (core async))
  )
)
</pre></div>
            <div class="highlight"><pre>$ jbuilder build barrier_bench.exe
    ocamldep barrier_bench.depends.ocamldep-output
      ocamlc barrier_bench.{cmi,cmo,cmt}
    ocamlopt barrier_bench.{cmx,o}
    ocamlopt barrier_bench.exe
$ ./_build/default/barrier_bench.exe -ascii alloc -quota 1
Estimated testing time 2s (2 benchmarks x 1s). Change using -quota SECS.
                                                                     
  Name        Time/Run   mWd/Run   mjWd/Run   Prom/Run   Percentage  
 ----------- ---------- --------- ---------- ---------- ------------ 
  mutable       8.22ms    2.00Mw     20.36w     20.36w      100.00%  
  immutable     4.30ms    5.00Mw                             52.32%  
                                                                     
</pre></div>

            <p>
	      There is a stark space/time trade-off here. The
              mutable version takes significantly longer to complete
              than the immutable one but allocates many fewer
              minor-heap words than the immutable version. Minor
              allocation in OCaml is very fast, and so it is often
              better to use immutable data structures in preference to
              the more conventional mutable versions. On the other
              hand, if you only rarely mutate a value, it can be faster
              to take the write-barrier hit and not allocate at
              all.</p>

            <p>
	      The only way to know for sure is to benchmark your
              program under real-world scenarios using
              <code>Core_bench</code> and experiment with the
              trade-offs. The command-line benchmark binaries have a
              number of useful options that affect garbage collection
              behavior:</p>
            <div class="highlight"><pre>$ ./_build/default/barrier_bench.exe -help
Benchmark for mutable, immutable

  barrier_bench.exe [COLUMN ...]

Columns that can be specified are:
	time       - Number of nano secs taken.
	cycles     - Number of CPU cycles (RDTSC) taken.
	alloc      - Allocation of major, minor and promoted words.
	gc         - Show major and minor collections per 1000 runs.
	percentage - Relative execution time as a percentage.
	speedup    - Relative execution cost as a speedup.
	samples    - Number of samples collected for profiling.

Columns with no significant values will not be displayed. The
following columns will be displayed by default:
	time alloc percentage

Error Estimates
===============
To display error estimates, prefix the column name (or
regression) with a '+'. Example +time.

(1) R^2 is the fraction of the variance of the responder (such as
runtime) that is accounted for by the predictors (such as number of
runs).  More informally, it describes how good a fit we're getting,
with R^2 = 1 indicating a perfect fit and R^2 = 0 indicating a
horrible fit. Also see:
http://en.wikipedia.org/wiki/Coefficient_of_determination

(2) Bootstrapping is used to compute 95% confidence intervals
for each estimate.

Because we expect runtime to be very highly correlated with number of
runs, values very close to 1 are typical; an R^2 value for 'time' that
is less than 0.99 should cause some suspicion, and a value less than
0.9 probably indicates either a shortage of data or that the data is
erroneous or peculiar in some way.

Specifying additional regressions
=================================
The builtin in columns encode common analysis that apply to most
functions. Bench allows the user to specify custom analysis to help
understand relationships specific to a particular function using the
flag "-regression" . It is worth noting that this feature requires
some understanding of both linear regression and how various quatities
relate to each other in the OCaml runtime.  To specify a regression
one must specify the responder variable and a command separated list
of predictor variables.

For example: +Time:Run,mjGC,Comp

which asks bench to estimate execution time using three predictors
namely the number of runs, major GCs and compaction stats and display
error estimates. Drop the prefix '+' to suppress error estimation. The
variables available for regression include:
	Time  - Time
	Cycls - Cycles
	Run   - Runs per sampled batch
	mGC   - Minor Collections
	mjGC  - Major Collections
	Comp  - Compactions
	mWd   - Minor Words
	mjWd  - Major Words
	Prom  - Promoted Words
	One   - Constant predictor for estimating measurement overhead


=== flags ===

  [-all-values]         Show all column values, including very small ones.
  [-ascii]              Display data in simple ascii based tables.
  [-ci-absolute]        Display 95% confidence interval in absolute numbers
  [-clear-columns]      Don't display default columns. Only show user specified
                        ones.
  [-display STYLE]      Table style (short, tall, line, blank or column).
                        Default short.
  [-fork]               Fork and run each benchmark in separate child-process
  [-geometric SCALE]    Use geometric sampling. (default 1.01)
  [-linear INCREMENT]   Use linear sampling to explore number of runs, example
                        1.
  [-load FILE]          Analyze previously saved data files and
                        don't run tests. [-load] can be specified multiple
                        times.
  [-no-compactions]     Disable GC compactions.
  [-overheads]          Show measurement overheads, when applicable.
  [-quota SECS]         Time quota allowed per test (default 10s).
  [-reduced-bootstrap]  Reduce the number of bootstrapping iterations
  [-regression REGR]    Specify additional regressions (See -? help).
  [-save]               Save benchmark data to &lt;test name&gt;.txt files.
  [-sexp]               Output as sexp.
  [-stabilize-gc]       Stabilize GC between each sample capture.
  [-v]                  High verbosity level.
  [-width WIDTH]        width limit on column display (default 200).
  [-build-info]         print info about this build and exit
  [-version]            print the version of this build and exit
  [-help]               print this help text and exit
                        (alias: -?)

</pre></div>

            <p>
	      The <code>-no-compactions</code> and
              <code>-stabilize-gc</code> options can help force a
              situation where your application has fragmented memory.
              This can simulate the behavior of a long-running
              application without you having to actually wait that long
              to re-create the behavior in a performance unit test.
              <a data-type="indexterm" data-startref="Hmh">&nbsp;</a></p>
          </section>
	</section>
      </section>

      <section id="attaching-finalizer-functions-to-values" data-type="sect1">
	<h1>Attaching Finalizer Functions to Values</h1>

	<p>
	  OCaml's automatic memory management guarantees that a
	  value will eventually be freed when it's no longer in use,
	  either via the GC sweeping it or the program terminating.
	  It's sometimes useful to run extra code just before a value
	  is freed by the GC, for example, to check that a file
	  descriptor has been closed, or that a log message is
	  recorded.

	  <a data-type="indexterm" data-primary="values" data-secondary="finalizer functions for">&nbsp;</a>
	  <a data-type="indexterm" data-primary="finalizers" data-secondary="in grabage collection">&nbsp;</a>
	  <a data-type="indexterm" data-primary="garbage collection" data-secondary="finalizer functions">&nbsp;</a></p>

	<div data-type="note">
          <h1>What Values Can Be Finalized?</h1>

          <p>
	    Various values cannot have finalizers attached since
            they aren't heap-allocated. Some examples of values that
            are not heap-allocated are integers, constant constructors,
            Booleans, the empty array, the empty list, and the unit
            value. The exact list of what is heap-allocated or not is
            implementation-dependent, which is why Core provides the
            <code>Heap_block</code> module to explicitly check before
            attaching the finalizer.</p>

          <p>
	    Some constant values can be heap-allocated but never
            deallocated during the lifetime of the program, for
            example, a list of integer constants.
            <code>Heap_block</code> explicitly checks to see if the
            value is in the major or minor heap, and rejects most
            constant values. Compiler optimizations may also duplicate
            some immutable values such as floating-point values in
            arrays. These may be finalized while another <span class="keep-together">duplicate</span> copy is being used by the
            program.</p>

          <p>
	    For this reason, attach finalizers only to values that
            you are explicitly sure are heap-allocated and aren't
            immutable. A common use is to attach them to file
            descriptors to ensure they are closed. However, the
            finalizer normally shouldn't be the primary way of closing
            the file descriptor, since it depends on the GC running in
            order to collect the value. For a busy system, you can
            easily run out of a scarce resource such as file
            descriptors before the GC catches up.</p>
	</div>

	<p>
	  Core provides a <code>Heap_block</code> module that
	  dynamically checks if a given value is suitable for
	  finalizing. This block is then passed to Async's
	  <code>Gc.add_finalizer</code> function that schedules the
	  finalizer safely with respect to all the other concurrent
	  program threads.

	  <a data-type="indexterm" data-primary="heaps" data-secondary="Heap_block module">&nbsp;</a></p>

	<p>
	  Let's explore this with a small example that finalizes
	  values of different types, some of which are heap-allocated
	  and others which are compile-time constants:</p>
	<div class="highlight"><pre><span></span><span class="k">open</span> <span class="nc">Core</span>
<span class="k">open</span> <span class="nc">Async</span>

<span class="k">let</span> <span class="o">attach_finalizer</span> <span class="o">n</span> <span class="n">v</span> <span class="o">=</span>
  <span class="k">match</span> <span class="nn">Heap_block</span><span class="p">.</span><span class="n">create</span> <span class="n">v</span> <span class="k">with</span>
  <span class="o">|</span> <span class="nc">None</span> <span class="o">-&gt;</span> <span class="o">printf</span> <span class="s2">&quot;%20s: FAIL</span><span class="se">\n</span><span class="s2">%!&quot;</span> <span class="o">n</span>
  <span class="o">|</span> <span class="nc">Some</span> <span class="o">hb</span> <span class="o">-&gt;</span>
    <span class="k">let</span> <span class="o">final</span> <span class="o">_</span> <span class="o">=</span> <span class="o">printf</span> <span class="s2">&quot;%20s: OK</span><span class="se">\n</span><span class="s2">%!&quot;</span> <span class="o">n</span> <span class="k">in</span>
    <span class="nn">Gc</span><span class="p">.</span><span class="n">add_finalizer</span> <span class="o">hb</span> <span class="o">final</span>

<span class="k">type</span> <span class="o">t</span> <span class="o">=</span> <span class="o">{</span> <span class="o">foo:</span> <span class="o">bool</span> <span class="o">}</span>

<span class="k">let</span> <span class="o">main</span> <span class="bp">()</span> <span class="o">=</span>
  <span class="k">let</span> <span class="o">alloced_float</span> <span class="o">=</span> <span class="nn">Unix</span><span class="p">.</span><span class="n">gettimeofday</span> <span class="bp">()</span> <span class="k">in</span>
  <span class="k">let</span> <span class="o">alloced_bool</span> <span class="o">=</span> <span class="o">alloced_float</span> <span class="o">&gt;</span> <span class="o">0.0</span> <span class="k">in</span>
  <span class="k">let</span> <span class="o">alloced_string</span> <span class="o">=</span> <span class="nn">String</span><span class="p">.</span><span class="n">create</span> <span class="o">4</span> <span class="k">in</span>
  <span class="o">attach_finalizer</span> <span class="s2">&quot;immediate int&quot;</span> <span class="mi">1</span><span class="o">;</span>
  <span class="o">attach_finalizer</span> <span class="s2">&quot;immediate float&quot;</span> <span class="mi">1</span><span class="o">.0;</span>
  <span class="o">attach_finalizer</span> <span class="s2">&quot;immediate variant&quot;</span> <span class="o">(`</span><span class="nc">Foo</span> <span class="s2">&quot;hello&quot;</span><span class="o">);</span>
  <span class="o">attach_finalizer</span> <span class="s2">&quot;immediate string&quot;</span> <span class="s2">&quot;hello world&quot;</span><span class="o">;</span>
  <span class="o">attach_finalizer</span> <span class="s2">&quot;immediate record&quot;</span> <span class="o">{</span> <span class="o">foo=</span><span class="bp">false</span> <span class="o">};</span>
  <span class="o">attach_finalizer</span> <span class="s2">&quot;allocated bool&quot;</span> <span class="o">alloced_bool;</span>
  <span class="o">attach_finalizer</span> <span class="s2">&quot;allocated variant&quot;</span> <span class="o">(`</span><span class="nc">Foo</span> <span class="o">alloced_bool);</span>
  <span class="o">attach_finalizer</span> <span class="s2">&quot;allocated string&quot;</span> <span class="o">alloced_string;</span>
  <span class="o">attach_finalizer</span> <span class="s2">&quot;allocated record&quot;</span> <span class="o">{</span> <span class="o">foo=alloced_bool</span> <span class="o">};</span>
  <span class="nn">Gc</span><span class="p">.</span><span class="n">compact</span> <span class="bp">()</span><span class="o">;</span>
  <span class="o">return</span> <span class="bp">()</span>

<span class="k">let</span> <span class="bp">()</span> <span class="o">=</span>
  <span class="nn">Command</span><span class="p">.</span><span class="n">async</span> <span class="o">~summary:</span><span class="s2">&quot;Testing finalizers&quot;</span>
    <span class="nn">Command</span><span class="p">.</span><span class="nn">Spec</span><span class="p">.</span><span class="n">empty</span> <span class="o">main</span>
  <span class="o">|&gt;</span> <span class="nn">Command</span><span class="p">.</span><span class="n">run</span>
</pre></div>

	<p>
	  Building and running this should show the following
	  output:</p>
  <div class="highlight"><pre>(jbuild_version 1)

(executable
  ((name barrier_bench)
   (modules barrier_bench)
   (libraries (core core_bench))
  )
)

(executable
  ((name finalizer)
   (modules finalizer)
   (libraries (core async))
  )
)
</pre></div>
	<div class="highlight"><pre>$ jbuilder build finalizer.exe
    ocamldep finalizer.depends.ocamldep-output
      ocamlc finalizer.{cmi,cmo,cmt}
    ocamlopt finalizer.{cmx,o}
    ocamlopt finalizer.exe
$ ./_build/default/finalizer.exe
       immediate int: FAIL
     immediate float: FAIL
   immediate variant: FAIL
    immediate string: FAIL
    immediate record: FAIL
      allocated bool: FAIL
    allocated record: OK
    allocated string: OK
   allocated variant: OK
</pre></div>

	<p>
	  The GC calls the finalization functions in the order of
	  the deallocation. If several values become unreachable during
	  the same GC cycle, the finalization functions will be called
	  in the reverse order of the corresponding calls to
	  <code>add_finalizer</code>. Each call to
	  <code>add_finalizer</code> adds to the set of functions,
	  which are run when the value becomes unreachable. You can
	  have many finalizers all pointing to the same heap block if
	  you wish.</p>

	<p>
	  After a garbage collection determines that a heap block
	  <code>b</code> is unreachable, it removes from the set of
	  finalizers all the functions associated with <code>b</code>,
	  and serially applies each of those functions to
	  <code>b</code>. Thus, every finalizer function attached to
	  <code>b</code> will run at most once. However, program
	  termination will not cause all the finalizers to be run
	  before the runtime exits.</p>

	<p>
	  The finalizer can use all features of OCaml, including
	  assignments that make the value reachable again and thus
	  prevent it from being garbage-collected. It can also loop
	  forever, which will cause other finalizers to be interleaved
	  with it.</p>
      </section>
    </section>
  </article></div><a class="next-chapter" href="22-compiler-frontend.html"><div class="content"><h1><small>Next: Chapter 22</small>The Compiler Frontend: Parsing and Type Checking</h1></div></a><footer><div class="content"><ul><li><a href="http://twitter.com/realworldocaml">@realworldocaml</a></li><li><a href="http://twitter.com/yminsky">@yminsky</a></li><li><a href="http://twitter.com/avsm">@avsm</a></li><li><a href="https://plus.google.com/111219778721183890368">+hickey</a></li><li><a href="https://github.com/realworldocaml">GitHub</a></li><li><a href="http://www.goodreads.com/book/show/16087552-real-world-ocaml">goodreads</a></li></ul><p>Copyright 2012-2014 Jason Hickey, Anil Madhavapeddy and Yaron Minsky.</p></div></footer><script src="js/jquery.min.js"></script><script src="js/min/app-min.js"></script><script src="js/discourse.js"></script></body></html>